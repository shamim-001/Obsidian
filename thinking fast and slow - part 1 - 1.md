[![Shortform App](https://www.shortform.com/img/logo-dark.70c1b072.svg)](https://www.shortform.com/app)

[Discover](https://www.shortform.com/app)

[Books](https://www.shortform.com/app/books)

[Articles](https://www.shortform.com/app/articles)

[My library](https://www.shortform.com/app/library)

[Search](https://www.shortform.com/app/search)

# Thinking, Fast and Slow

[Back to Discover](https://www.shortform.com/app)

## Part 1-1: Two Systems of Thinking

We believe we’re being rational most of the time, but really **much of our thinking is automatic**, done subconsciously by instinct. Most impressions arise without your knowing how they got there. Can you pinpoint exactly how you knew a man was angry from his facial expression, or how you could tell that one object was farther away than another, or why you laughed at a funny joke?

This becomes more practically important for the decisions we make. Often, **we’ve decided what we’re going to do before we even realize it**. Only _after_ this subconscious decision does our rational mind try to justify it.

The brain does this to save on effort, substituting easier questions for harder questions. Instead of thinking, “should I invest in Tesla stock? Is it priced correctly?” you might instead think, “do I like Tesla cars?” The insidious part is, **you often don’t notice the substitution**. This type of substitution produces systematic errors, also called biases. We are blind to our blindness.

### System 1 and System 2 Thinking

In _Thinking, Fast and Slow_, Kahneman defines two systems of the mind:

**System 1**: operates automatically and quickly, with little or no effort, and no sense of voluntary control

- Examples: Detect that one object is farther than another; detect sadness in a voice; read words on billboards; understand simple sentences; drive a car on an empty road.

**System 2**: allocates attention to the effortful mental activities that demand it, including complex computations. Often associated with the subjective experience of agency, choice and concentration

- Examples: Focus attention on a particular person in a crowd; exercise faster than is normal for you; monitor your behavior in a social situation; park in a narrow space; multiply 17 x 24.

#### Properties of System 1 and 2 Thinking

System 1 can be completely involuntary. You can’t stop your brain from completing 2 + 2 = ?, or from considering a cheesecake as delicious. You can’t unsee [optical illusions](https://en.wikipedia.org/wiki/M%C3%BCller-Lyer_illusion), even if you rationally know what’s going on.

System 1 can arise from expert intuition, trained over many hours of learning. In this way a chess master can recognize a strong move within a second, where it would take a novice several minutes of System 2 thinking.

System 2 requires attention and is disrupted when attention is drawn away. More on this next.

System 1 automatically generates suggestions, feelings, and intuitions for System 2. **If endorsed by System 2, intuitions turn into beliefs, and impulses turn into voluntary actions.**

System 1 can detect errors and recruits System 2 for additional firepower.

- Kahneman tells a story of a veteran firefighter who entered a burning house with his crew, felt something was wrong, and called for them to get out. The house collapsed shortly after. He only later realized that his ears were unusually hot but the fire was unusually quiet, indicating the fire was in the basement.

Because System 1 operates automatically and can’t be turned off, biases are difficult to prevent. Yet it’s also not wise (or energetically possible) to constantly question System 1, and System 2 is too slow to substitute in routine decisions. “**The best we can do is a compromise: learn to recognize situations in which mistakes are likely and try harder to avoid significant mistakes when the stakes are high.”**

In summary, most of what you consciously think and do originates in System 1, but System 2 takes over when the situation gets difficult. System 1 normally has the last word.

### A Lazy System 2 Accepts the Errors of System 1

Consider these questions, and go through them quickly, trusting your intuition.

> 1) A bat and ball cost $1.10. The bat costs one dollar more than the ball. How much does the ball cost?
> 
> 2) How many murders happen in Michigan each year?
> 
> 3) Does the conclusion follow from the premises?
> 
> - All roses are flowers.
>     
> - Some flowers fade quickly.
>     
> - Therefore, some roses fade quickly.
>     

Ready to see the answers?

1) The answer is $0.05. The common intuitive (and wrong) answer is $0.10.

2) The trick is whether you remember that Detroit is in Michigan. People who remember this estimate a number that is much higher (and more accurate) than those who forget.

3) The answer is no—all roses may not fit into the subcategory of flowers that fade quickly.

===

All of your answers, if you really spent time on it, _could_ be verified by deliberate System 2 thinking. In the first question, it’s easy to see that if the ball cost $0.10, the total would be $1.20, which is clearly incompatible with the question. For the second question, if you had to enumerate the major cities of Michigan, you would likely list Detroit.

For some people, spending enough time would be sufficient to get the answers right. But **many people, even if given unlimited time, might not even _think_ to apply their System 2 to question their answers** and find different approaches to the question. Over 50% of students at Harvard and MIT gave the wrong answer to the bat-and-ball question; over 80% at less selective universities.

This is the insidious problem of a “lazy System 2.” System 1 surfaces the intuitive answer for System 2 to evaluate. **But a lazy System 2 doesn’t properly do its job** - it accepts what System 1 offers without expending the small investment of effort that could have rejected the wrong answer.

Even worse, this aggravates confirmation bias. A piece of information that fits your prior beliefs might evoke a positive System 1 feeling, while your System 2 might never pause to evaluate the validity of the piece of information. **If you believe a conclusion is true, you might believe arguments that support it, even when the arguments are unsound.**

It’s useful then to distinguish between intelligence and rationality.

- Intelligence might be considered the full computational horsepower of a person’s brain.
- Rationality is resistance to mental laziness; **not accepting a superficially plausible answer**; being more skeptical of intuitions; tending to put in the hard work of checking the logic; and thus immunity to biases.

In other words, a powerful system 2 is useless if the person doesn’t recognize the need to override their system 1 response.

The theme here, that will recur through the book, is that **people are overconfident and place too much faith in their intuitions**. Further, they find cognitive effort unpleasant and avoid it as much as possible.

[

Previous

1-Page Summary

](https://www.shortform.com/app/book/thinking-fast-and-slow/1-page-summary)

[

Next

Part 1-2: System 2 Has a Maximum Capacity

](https://www.shortform.com/app/book/thinking-fast-and-slow/part-1-2)