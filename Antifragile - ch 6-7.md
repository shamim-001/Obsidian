[![Shortform App](https://www.shortform.com/img/logo-dark.70c1b072.svg)](https://www.shortform.com/app)

[Discover](https://www.shortform.com/app)

[Books](https://www.shortform.com/app/books)

[Articles](https://www.shortform.com/app/articles)

[My library](https://www.shortform.com/app/library)

[Search](https://www.shortform.com/app/search)

# Antifragile

[Back to Search](https://www.shortform.com/app/search)

## Chapters 6-7: Randomness Is Necessary

The previous chapters have shown the trends of antifragile systems: They improve after encountering some small degree of randomness, and they get stronger from (minor) damage. We’ve also discussed how controlling such a system too tightly will eventually backfire, perhaps catastrophically. In this chapter we’ll further explore the benefits of adding randomness to a system and, conversely, the dangers of over-intervening in naturally antifragile systems.

The philosopher Jean de Buridan proposed a thought experiment: A donkey who is equally hungry and thirsty, placed at an exactly equal distance from water in one direction and food in the other, won’t be able to decide which way to go. It’ll be stuck in that spot until it dies of hunger or thirst.

However, we can help Buridan’s donkey by adding a small dose of randomness to the system. Giving the donkey a small push in one direction or the other will put it closer to either the food or the water, allowing it to finally make a decision and thereby saving its life. Which direction you push doesn’t matter—as long as _something_ changes, the balance is broken and the donkey is saved.

### Annealing—Real, Simulated, and Political

In metallurgy, _annealing_ is a process used to make metal stronger and remove impurities. It involves heating the metal and then carefully cooling it. The increased energy from heating the metal excites the atoms and breaks them out of their current positions, then the controlled cooling gives them the chance to find new, stronger arrangements. In other words, introducing a short period of randomness to the system produces a stronger product.

Mathematicians have developed a computer simulation technique inspired by annealing and called—appropriately enough—_simulated annealing_. Rather than immediately trying to find the best solution to a given problem, the computer will also accept less effective solutions, because they might be near to the _actual_ best solution.

To visualize simulated annealing, imagine a graph with numerous peaks and dips, some higher than others. A computer looking for the highest point on the graph might find one of those peaks, check to either side of it and find that the graph is going down, and determine that it’s found the best solution. However, a computer using simulated annealing would randomly pick various points on the graph and search for the highest point to either side of those points. By doing so, it’s more likely to find the actual highest point.

The annealing process applies to politics, too, and has since ancient times. Athenian assemblies, for example, were chosen by lottery. Much more recently, the physicist and mathematician Alessandro Pluchino used a computer simulation to show that a certain number of randomly selected members can make a parliament function more effectively, perhaps because those people bring different perspectives and ideas with them.

Nor was politics the only area where ancient Greeks took advantage of randomness; they used various methods of getting random results and called it _divination_. An Athenian faced with a difficult choice might open Virgil’s _Aeneid_ to a random page and interpret the first line she sees as advice from the gods. This would allow her to proceed with confidence that her path had been ordained by a higher power, without anxiety over the outcome—after all, even if it’s disastrous, it’s not _her_ fault.

Another way to reshuffle political structures is the time-honored tradition of assassination. Killing an important political figure often shakes others loose from their established roles as they scramble around to fill the sudden void in their power structure. One very public example of this was when mafioso John Gotti killed the capo of his family and took his place.

**In both metals and politics, long periods of stability—or, worse, enforced stability, as we discussed earlier—allow impurities to gather beneath the surface and destabilize the whole structure.** In the case of metals, this simply leads to a weaker material; in the case of politics, it often leads to violent and messy blowups, up to and including civil wars.

### “Modernity” Is Enforced Stability

We touched on how modern society enforces stability back in Chapter 3 with the concept of touristification—removing the risk and randomness from everything, thereby making us tourists in our own lives. But how does this happen?

Remember the Athenians and their reliance on divination. They believed that it was the gods, not humans, who had ultimate control. They may not have truly believed that it was randomness running the world, but they attributed control to some vast, unknowable, and inhuman power. Functionally, it was the same thing.

However, this changes with the onset of _rationalization_: the idea that the world, and society itself, can be understood and controlled in every facet. Rationalization replaces reliance on the gods with reliance on science and predictive models, and it replaces worshipping at altars with worshipping at flags. It is, in short, humans trying to take power and agency away from random chance (or the gods, or whatever you want to call it).

Once people start thinking that they can control society, they start working to force everyone into the roles they imagine. They reduce people to what is useful, and they try to optimize every aspect of civilization to run as efficiently as possible.

The problem is that such people don’t understand antifragility. Rather than seeing randomness and minor problems as ways to ultimately strengthen their society, they see only inefficiency and obstacles. They try to suppress or eliminate any such obstacles that get in the way of their society’s gears turning smoothly, forever. Of course, as we’ve said before, that only leads to a buildup of invisible problems that eventually tear their orderly society apart.

The real downfall of modernity and rationalization is people’s inability to distinguish between major and minor problems. That’s not a personal failing, it’s simply a human limitation. The sheer amount of information, conflict, and general noise in the world makes it impossible for anyone to properly track and categorize it all; therefore, instead of calmly and methodically dealing with the most serious issues, people try to fix _all_ of them. In doing so, they undermine society’s natural antifragility, and they drive themselves crazy in the process.

#### First, Do No Harm

**Modernity and rationalization are born from the naive idea that human intervention can improve on natural randomness.** One example of how this is fatally flawed is the field of _iatrogenics_: the harm caused by medical intervention.

Throughout history, many people who would have survived unattended have died under the care of doctors. Part of the problem was medical error, but iatrogenics reached its height around the late 19th century with the onset of large-scale clinics and hospitals. Before people knew what germs were, patients were subjected to unsanitized beds, floors, and hands, and died in droves from so-called “hospital fever.” It was only from the 20th century onward that medicine, on average, did more good than harm, largely thanks to antibiotics.

However, modern medicine in particular has a different form of iatrogenics, which arises from conflicts of interest between the professionals and their patients. The most familiar example of this may be the perceived overprescription of painkillers, psychiatric meds, and so on. A doctor who gets kickbacks from drug companies for prescribing their drugs has a clear conflict of interest, one that is obviously harmful to his or her patients.

This is called the _agency problem_: The one making decisions (the agent) is doing so for his or her own benefit rather than the benefit of the clients. While iatrogenics originated in medicine, it and the agency problem occur in numerous fields. No matter the field, though, it starts with modern, “rational” people thinking that their intervention will make things better.

Iatrogenics also has an opposite; that is, when attempting to harm something makes it stronger. An example is the fierce critics of Ayn Rand who, as we mentioned earlier, ended up spreading her ideas by attacking them. There’s not a word for this specific situation, but it’s clearly an application of antifragility.

#### The Fragility of Theories

Scientific theories are a key underpinning of rationalization and a dangerous one. Scientists frequently promote theories without stopping to consider the damage that might happen if those theories are wrong.

Think back on the clinics from the previous section: The theory (albeit not a scientific one) was that having a large number of medical professionals and equipment together in the same place, and bringing patients there, would make treatment more efficient and effective. Instead, countless patients died of “hospital fever.”

Furthermore, science—that is, rigorous testing and observation—can be done without resorting to theories at all. There’s even a name for it: _phenomenology_, the study of phenomena that currently have no theories explaining them. While theories are fragile and often vanish as quickly as they appear, phenomena are durable; they happen the same way every time.

Social sciences are especially vulnerable to flawed theories, and even the theories themselves seem to vary wildly from one school of thought to another. In the cold war years, the University of Chicago was pushing laissez faire economics while the University of Moscow taught the complete opposite. Even calling such ideas “theories” stretches the definition a bit because theories are supposed to be closely examined and supported with concrete evidence.

At any rate, it seems clear that our modern world needs a method to deal with the fragility of theories and the actions we take based on them. Such errors were harmful enough in medicine, where the risk and cost were spread out over large numbers of people. In social sciences and politics, where power is so highly concentrated, things tend to go wrong quickly and explosively.

### When and How to Intervene

All this discussion of modernity and rationalism may have given the false impression that human intervention is _always_ harmful, but that’s not the case. We just need to think more carefully about where, when, and how we intervene.

In medicine, doctors who overprescribe drugs and order excessive tests are over-intervening—and, ironically, under-intervening at the same time—because all that extra work has minimal results. It would be better to save those resources for where intervention is truly needed, like emergency situations.

**The general argument here is that some areas need human intervention, while others are harmed by it.** For instance, we need strong legal interventions to keep large corporations from ruining both the economy and the environment. However, minor injuries and illnesses don’t need medical intervention, and in fact, seeking it may cause more harm.

So, clearly, the next step is to identify exactly what areas we need to intervene in and when. **As a rule of thumb, limiting size, concentration, and speed are helpful methods of harm reduction.**

A corporation that gets too big has an unreasonably large impact on the economy; therefore, breaking up monopolies helps keep prices down and wages up. We’ve already discussed how concentrating too much power in one place is dangerous and ultimately harmful (a powerful top-down government versus Switzerland’s collection of local cantons). Finally, imposing speed limits on highway drivers has proven to reduce the frequency and severity of accidents. These are only examples—there are many other ways in which limiting size, concentration, and speed are helpful forms of damage control.

However, while intervening in highway driving has proven to be helpful, intervening in city driving may be just the opposite. A town called Drachten, in the Netherlands, ran an experiment where it removed all of its street signs. Surprisingly, this deregulation actually led to _increased_ road safety. Although, perhaps it isn’t actually surprising, but just an example of the antifragility of attention. Drivers performed better when subjected to the stress of observing and reacting to their surroundings, rather than placidly obeying street signs.

The difference is, again, a matter of speed. Regulations or no, it’s simply not possible to reach highway speeds while driving on surface streets, and therefore highway driving comes with different (and increased) risks.

In short, what we need is a methodical and organized protocol that we can use to determine where, when, and how much to intervene. Given the massive potential (and actual) iatrogenics of modern life—environmental damage, stifled antifragility, and the inevitable threat of nuclear war, to name a few—the time will come when we need to intervene. Intervening in the right ways might be the difference between a living, thriving world and annihilation.

#### Procrastination as Risk-Management

Given modern humans’ tendency to intervene in everything, we view hesitating to intervene—that is, procrastinating—as some kind of defect or sickness. The supposed “cures” range from changing your environment, to pursuing a new career, to simply powering through it. The problem is compounded by the fact that inaction is hardly ever rewarded; you get a bonus for the problem you solve, not the one that never happens in the first place.

However, in many cases, procrastination is your body trying to tell you something important. For example, an author who procrastinates on writing a book may be doing so because it’s not what he or she should be writing about, either because of lack of expertise or lack of interest. For a more dramatic example, the Roman general Fabius Maximus irritated the conqueror Hannibal to no end by repeatedly delaying and avoiding military engagements that he was sure to lose. In Maximus’s situation, procrastination was the best strategy and indeed the only viable one.

In other situations, most notably emergencies, there’s no sense of procrastination at all. A firefighter doesn’t “get around to” putting out a house fire, and someone who’s severely injured doesn’t put off going to the hospital. When immediate action is needed, people will act.

All of this suggests that procrastination is a natural risk-management mechanism, an ingrained instinct to let antifragile systems work out their own problems. **Millions of years of evolution have given us the tendency to procrastinate, so there must be a good reason for it.** Usually that reason is not that the procrastinator is defective, but that his or her environment is.

[

Previous

Chapter 5: Variation Leads to Stability

](https://www.shortform.com/app/book/antifragile/chapter-5)

[

Next

Chapters 8-11: The Fragility of Predictions

](https://www.shortform.com/app/book/antifragile/chapters-8-11)