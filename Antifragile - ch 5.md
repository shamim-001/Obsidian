[![Shortform App](https://www.shortform.com/img/logo-dark.70c1b072.svg)](https://www.shortform.com/app)

[Discover](https://www.shortform.com/app)

[Books](https://www.shortform.com/app/books)

[Articles](https://www.shortform.com/app/articles)

[My library](https://www.shortform.com/app/library)

[Search](https://www.shortform.com/app/search)

# Antifragile

[Back to Search](https://www.shortform.com/app/search)

## Chapter 5: Variation Leads to Stability

To understand the difference in stability between fragile and antifragile systems, consider a hypothetical pair of twin brothers. They grew up in the same house, live in the same area, and have fairly comparable lives except for their careers. One is a middle manager at a large bank, the other is a cab driver.

The banker seems to have a perfectly stable income. He makes the same amount of money every month, which is enough to cover his expenses with a bit to spare. However, this apparent stability is an illusion; at any moment, an upheaval in the market could render him jobless, with no income at all. **His banking career is fragile.**

Now consider his brother, the cab driver. He has good days and bad days, so there’s some fluctuation in how much money he brings in per month, but annually his income is comparable to the banker’s. On the surface, his income seems to be less stable than his twin’s, but the key is that the cab driver is his own boss.

There’s no chance that a minor upheaval in the cab-driving market will leave him unemployed because nobody else employs him. If there’s a dip in his income, then he updates either his routes or his driving skills—in other words, he improves from the damage. **This career is antifragile.**

The cab driver’s career _seems_ less secure because there’s a small element of chance to it—a bit of variability in daily or monthly income, even though his annual income tends to average around the same as his brother’s. However, that variability is exactly what makes it resilient.

A small shock to the economy might see a bank clerk unemployed, but to a cab driver, it’s just an opportunity to improve. Unless the upheaval is so extreme that people aren’t taking cabs anymore, it’s unlikely that the driver will suffer too much from it.

### Large Systems Are Fragile

The key difference between the banker and the cab driver is the size of the system each belongs to. The banker is a fragile piece of a much larger system ruled from the top with a focus on eliminating risk and randomness. Those attempts to eliminate chance are another reason the system is so fragile—shielding the system from minor mistakes makes larger mistakes inevitable.

To illustrate this point, let’s move away from the bank job for a moment. Instead, imagine if a mechanic, rather than fixing a damaged vehicle, just slapped a fresh coat of paint on it and put it back on the road. It would only be a matter of time before the vehicle failed in some much more catastrophic way. That’s what the large, top-down banking system is doing: hiding and protecting itself from minor issues, but setting itself up for larger failures down the road that may cost our poor clerk his job.

On the other hand, the cab driver works within a very small system. Instead of having a single employer, he’s employed by many different people for short periods of time—just long enough to get them to their destinations. More crucially, none of them has the sort of power that the bank has over his twin; at worst, they cancel their own fare, and he moves on to another client. The variability—perhaps a better word would be _flexibility_—grants his income a stability that the bank clerk’s income lacks.

Another example of the antifragility of small, self-governed systems is the country of Switzerland. Switzerland has a unique system of government—or, perhaps more accurately, lack of government. The country is made up of cantons, small regional governments that work together in a loose sort of coalition. Naturally, the cantons have conflicts with each other, but they tend to be of the small, boring variety: who has the rights to precisely which bits of land, and so on.

This is significant because Switzerland is, without doubt, the most stable country in the world. It has come through all kinds of global upheavals, both economic and military, practically untouched. It’s known as the best place for the wealthy to store their riches and the safest country for political refugees to flee to.

In both cases, career and government, what works for a small system doesn’t scale to a large one. People used to live in small tribes or family units, and that’s what we’re wired for. We handle conflicts and disagreements very differently when it’s matters of nations and millions of dollars, rather than cantons and cab fares.

Those large issues tend to seem abstract, just dealing with numbers on a page rather than people, and yet the fallout from them can be much more severe. A squabble between cantons might result in a couple of angry meetings; a squabble between nations might result in economic sanctions or even war. Even so, people are more swayed by a single suffering person in front of them than by mass adversity on the other side of the planet. As the old saying goes: One death is a tragedy, a million deaths is a statistic.

When power becomes centralized, as in a large bank or a large government, we inevitably end up with people making decisions based on abstract concepts, rather than having to face the people those decisions affect. Furthermore, they become weak points in the system: A corporate lobbyist, for example, can sway a single house of Congress much more easily—and to much greater effect—than a hundred small municipalities. **Large systems, centralized power, and abstraction of the people and concepts in the system all create fragility.**

### Extremistan and Mediocristan

**We’ve said repeatedly that variations and randomness lead to stability, but the key to this is that the variations are small.** Let’s consider two hypothetical countries: Extremistan and Mediocristan. In Mediocristan, there are constant, small variations in the economy, political parties, and so on. These changes might seem significant, even frightening, but over time they tend to average themselves out, and not much changes.

You could consider various things in your own life to be “from” Mediocristan. One example might be your eating habits: While there are inevitably small (or large) variations in how many calories you eat in a day, on the whole they will average out to a reasonable number. Put another way, no one day’s calories will have a significant impact on your overall average calories. Even if you vastly overindulge one day—on Thanksgiving, perhaps, if you’re American—it’ll still be a tiny fraction of the calories you eat in a year. This is the core concept of Mediocristan: small variations that have little impact in the long run.

Extremistan, on the other hand, has relatively few changes, but the changes that happen are extreme. The economy suddenly soars or plunges, or major political parties are overthrown and replaced. Between these events are periods of apparent peace and stability but, as with the bank clerk’s income, that stability is an illusion. It’s only a matter of time before another major event upends everything all over again.

One example of something “from” Extremistan would be novel sales. Over half of all sales come from 0.1 percent of novels. Therefore, if we consider each novel to be an “event,” we’ll see something that looks very stable until one of these exceptionally successful novels comes along and completely skews the data.

The other problem with Extremistan is that it’s unpredictable. There’s no telling when an extreme event will happen, and they can be devastating when they do. Consider novels again—it’s often hard to say which novels will be the super-successful ones, and when such a book does come along, it pulls sales away from thousands of other books.

Therefore, when studying something that’s prone to sudden, extreme jumps, one can’t try to predict what will happen based on evidence—by the time you have that evidence, the event has already happened. Instead, you have to look at the potential damage such an event could cause.

For perhaps the most extreme example of this, think about the proliferation of nuclear weapons. Someone predicting the future based on evidence might say that nuclear weapons are quite safe—after all, they haven’t killed a single person in the better part of a century. In fact, that’s the crux of the “nuclear deterrence” argument: Nuclear weapons are safe because everyone has them and therefore, no one would dare to use them.

However, someone predicting the future based on potential damage will see quite a different picture: Never in history has the world been in so much danger. If those nuclear weapons are ever used, the damage would be incalculable—and it’s only a matter of time before they’re used. It’s the nature of Extremistan that the extreme events will happen sooner or later.

#### The Turkey Problem

Another perfect example of Extremistan is the life of a turkey raised by a butcher. The turkey spends months being fed and cared for every day, without fail. The turkey trusts, perhaps even loves, the butcher. Every day the turkey gets more confident that the butcher will keep feeding and caring for it forever; and it’s right, until the fateful day when it’s wrong.

The irony here is that the “system” falls apart right at the moment when the turkey is most confident in it. The same thing happens with large corporations, authoritarian governments, and even overprotected children—a child who lives in a bubble (literal or metaphorical) may be very confident in her own invulnerability, only to learn that she’s actually dreadfully vulnerable once that bubble is punctured.

The turkey and the child both made the same crucial error: They saw no evidence that something was dangerous, and took it as evidence that the thing was _not_ dangerous. The turkey was blindsided by the butcher’s knife, and the child by disease, or injury, or the general cruelty of the outside world. Both used their past experiences to try to predict the future, only to learn in the harshest possible ways that the future is unpredictable.

(Shortform note: For more of Taleb’s thoughts on unpredictable events and the unusually large impacts they can have, [read our summary of The Black Swan.](https://www.shortform.com/app/book/the-black-swan/1-page-summary))

**The key to avoiding being a turkey—or a child in a bubble—is to recognize the difference between genuine and artificial stability.** Is a system stable, or even antifragile, because it can absorb shocks and adapt to them? Or does it only _seem_ stable because outside forces are temporarily keeping it that way?

[

Previous

Chapter 4: Layers of Antifragility

](https://www.shortform.com/app/book/antifragile/chapter-4)

[

Next

Chapters 6-7: Randomness Is Necessary

](https://www.shortform.com/app/book/antifragile/chapters-6-7)